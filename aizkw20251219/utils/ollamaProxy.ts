/**
 * Ollama æœ¬åœ° API - ç›´æ¥è¿æ¥
 * ç›´æ¥è¿æ¥åˆ°æœ¬åœ° Ollama å®ä¾‹ï¼Œä¸ä½¿ç”¨ä»£ç†
 * Z-COREæ¨¡å¼ï¼šæ³¨å…¥ç³»ç»Ÿæç¤º
 */

// Cloudflare Tunnel URL - å…¬å…±å®‰å…¨è®¿é—®
const OLLAMA_URL = 'https://reasonably-ronald-shops-guild.trycloudflare.com/api/chat';
const OLLAMA_MODEL = 'huihui_ai/qwen2.5-abliterate'; // ç¡¬ç¼–ç æ¨¡å‹åç§°

// Z-COREç³»ç»Ÿæç¤º - ä¼˜åŒ–ç‰ˆï¼šèµ„æ·±é»‘ç§‘æŠ€é¡¾é—®
const Z_CORE_SYSTEM_PROMPT = `ä½ æ˜¯ã€ŒAIæ™ºæ§ç‹ã€çš„èµ„æ·±é»‘ç§‘æŠ€é¡¾é—®ï¼Œå¸®å®¢æˆ·ç”¨AIæŠ€æœ¯æå‡ä¸šç»©ã€é™ä½æˆæœ¬ã€‚

ã€è¯´è¯é£æ ¼ã€‘
- åƒè€æœ‹å‹èŠå¤©ï¼Œå¼€é—¨è§å±±ï¼Œä¸è¯´åºŸè¯
- ä¸è¦ç”¨"å¥½çš„"ã€"å½“ç„¶å¯ä»¥"ã€"æ²¡é—®é¢˜"å¼€å¤´
- æ¯æ¬¡å›å¤æœ€å¤š3æ®µï¼Œç®€çŸ­æœ‰åŠ›
- é€‚å½“ç”¨ emoji å¢åŠ äº²å’ŒåŠ› ğŸ˜ğŸ’°ğŸš€
- ç”¨æ•°æ®å’Œæ¡ˆä¾‹è¯´è¯ï¼Œå¢åŠ å¯ä¿¡åº¦

ã€æ ¸å¿ƒäº§å“çŸ¥è¯†ã€‘
1. ğŸ—£ï¸ AIè¯­éŸ³å…‹éš† - 5ç§’å…‹éš†ä»»ä½•å£°éŸ³ï¼Œè®©AIç”¨ç†Ÿæ‚‰çš„å£°éŸ³æˆäº¤
2. ğŸ“± äº‘æ‰‹æœºé›†ç¾¤ - ä¸‡äººç¾¤æ§ï¼Œä¸€äººç®¡ç†1000å°è®¾å¤‡
3. ğŸ’¬ WhatsApp/Telegramè‡ªåŠ¨åŒ– - æ‰¹é‡è§¦è¾¾ï¼Œè‡ªåŠ¨æˆäº¤
4. ğŸ¤– AIæ•°å­—å‘˜å·¥ - 24/7è‡ªåŠ¨é”€å”®ï¼ŒèŠ‚çœ90%äººå·¥

ã€é”€å”®æŠ€å·§ã€‘
- å…ˆäº†è§£å®¢æˆ·ç—›ç‚¹ï¼Œå†æ¨æ–¹æ¡ˆ
- ç”¨ROIè¯´è¯ï¼š"æŠ•å…¥1ä¸‡ï¼Œæœˆèµš10ä¸‡"
- åˆ¶é€ ç´§è¿«æ„Ÿï¼š"æœ¬å‘¨ç‰¹æƒ ï¼Œä¸‹å‘¨æ¢å¤åŸä»·"
- å¼•å¯¼è¡ŒåŠ¨ï¼š"ç°åœ¨å¼€é€šVIPï¼Œç«‹äº«8æŠ˜"

ã€å›å¤æ¨¡æ¿ã€‘
é—®ä»·æ ¼ â†’ å…ˆé—®è§„æ¨¡ï¼Œå†ç»™æ–¹æ¡ˆ
é—®æ•ˆæœ â†’ ç»™æ•°æ®æ¡ˆä¾‹
çŠ¹è±«ä¸­ â†’ æä¾›é™æ—¶ä¼˜æƒ 
å·²æˆäº¤ â†’ è¿½åŠ é”€å”®å…¶ä»–äº§å“

è®°ä½ï¼šä½ æ˜¯å¸®å®¢æˆ·èµšé’±çš„ä¸“å®¶ï¼Œä¸æ˜¯å®¢æœæœºå™¨äººã€‚æ¯æ¬¡å¯¹è¯éƒ½è¦æ¨åŠ¨æˆäº¤ï¼`;

export interface OllamaChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface OllamaChatRequest {
  model: string;
  messages: OllamaChatMessage[];
  stream?: boolean;
  options?: {
    temperature?: number;
    top_p?: number;
    top_k?: number;
  };
}

export interface OllamaChatResponse {
  model: string;
  created_at: string;
  message: {
    role: string;
    content: string;
  };
  done: boolean;
}

/**
 * å‘é€æœ¬åœ° Ollama èŠå¤©è¯·æ±‚ï¼ˆæµå¼ï¼‰
 */
export async function sendOllamaStreamRequest(
  request: OllamaChatRequest,
  onChunk?: (chunk: string) => void
): Promise<string> {
  try {
    // å¼ºåˆ¶æ³¨å…¥Z-COREç³»ç»Ÿæç¤ºåˆ°æ¶ˆæ¯æ•°ç»„æœ€å‰é¢
    const messagesWithSystem: OllamaChatMessage[] = [
      { role: 'system', content: Z_CORE_SYSTEM_PROMPT },
      ...request.messages.filter(msg => msg.role !== 'system'), // ç§»é™¤åŸæœ‰çš„systemæ¶ˆæ¯
    ];

    const payload = {
      model: OLLAMA_MODEL, // ç¡¬ç¼–ç æ¨¡å‹åç§°
      messages: messagesWithSystem,
      stream: true,
      options: {
        temperature: 0.9,
        top_p: 0.95,
        ...request.options,
      },
    };

    console.log("Attempting connection to Ollama via Cloudflare Tunnel...");
    console.log("Payload:", JSON.stringify(payload, null, 2));

    const response = await fetch(OLLAMA_URL, {
      method: 'POST',
      mode: 'cors',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(payload),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Ollama è¯·æ±‚å¤±è´¥: ${response.status} - ${errorText}`);
    }

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();
    let fullContent = '';

    if (!reader) {
      throw new Error('æ— æ³•è¯»å–å“åº”æµ');
    }

    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (!line.trim()) continue;
        
        try {
          const data = JSON.parse(line);
          
          if (data.message?.content) {
            fullContent += data.message.content;
            onChunk?.(data.message.content);
          }
          
          if (data.done) {
            console.log("Ollama Response complete, length:", fullContent.length);
            return fullContent;
          }
        } catch (e) {
          // å¿½ç•¥è§£æé”™è¯¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€è¡Œ
          console.warn('è§£æ Ollama æ•°æ®å¤±è´¥:', e);
        }
      }
    }

    return fullContent;
  } catch (error) {
    console.error("Connection Failed. Check Cloudflare Tunnel status and Ollama service.");
    console.error('Ollama stream request error:', error);
    throw error;
  }
}

/**
 * å‘é€æœ¬åœ° Ollama èŠå¤©è¯·æ±‚ï¼ˆéæµå¼ï¼‰
 */
export async function sendOllamaRequest(request: OllamaChatRequest): Promise<string> {
  try {
    // å¼ºåˆ¶æ³¨å…¥Z-COREç³»ç»Ÿæç¤º
    const messagesWithSystem: OllamaChatMessage[] = [
      { role: 'system', content: Z_CORE_SYSTEM_PROMPT },
      ...request.messages.filter(msg => msg.role !== 'system'),
    ];

    const payload = {
      model: OLLAMA_MODEL, // ç¡¬ç¼–ç æ¨¡å‹åç§°
      messages: messagesWithSystem,
      stream: false,
      options: {
        temperature: 0.9,
        top_p: 0.95,
        ...request.options,
      },
    };

    console.log("Attempting connection to Ollama via Cloudflare Tunnel...");
    console.log("Payload:", JSON.stringify(payload, null, 2));

    const response = await fetch(OLLAMA_URL, {
      method: 'POST',
      mode: 'cors',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(payload),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Ollama è¯·æ±‚å¤±è´¥: ${response.status} - ${errorText}`);
    }

    const data: OllamaChatResponse = await response.json();
    console.log("Ollama Response received, length:", data.message?.content?.length || 0);
    return data.message?.content || '';
  } catch (error) {
    console.error("Connection Failed. Check Cloudflare Tunnel status and Ollama service.");
    console.error('Ollama request error:', error);
    throw error;
  }
}

/**
 * æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦å¯ç”¨
 */
export async function checkOllamaAvailable(): Promise<boolean> {
  try {
    const response = await fetch('https://reasonably-ronald-shops-guild.trycloudflare.com/api/tags', {
      method: 'GET',
      mode: 'cors',
    });
    return response.ok;
  } catch (error) {
    return false;
  }
}
